"use strict";(self.webpackChunksap_ai_sdk_documentation=self.webpackChunksap_ai_sdk_documentation||[]).push([[5764],{4612:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>s,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"langchain/openai","title":"OpenAI Integration","description":"How to integrate Azure OpenAI chat and embedding clients from SAP Cloud SDK for AI into LangChain.","source":"@site/docs-js/langchain/openai.mdx","sourceDirName":"langchain","slug":"/langchain/openai","permalink":"/ai-sdk/docs/js/langchain/openai","draft":false,"unlisted":false,"editUrl":"https://github.com/SAP/ai-sdk/edit/main/docs-js/langchain/openai.mdx","tags":[],"version":"current","frontMatter":{"id":"openai","title":"OpenAI Integration","hide_title":false,"hide_table_of_contents":false,"description":"How to integrate Azure OpenAI chat and embedding clients from SAP Cloud SDK for AI into LangChain.","keywords":["sap","cloud","sdk","ai","langchain","openai"]},"sidebar":"docsJsSidebar","previous":{"title":"Orchestration Integration","permalink":"/ai-sdk/docs/js/langchain/orchestration"},"next":{"title":"AI API","permalink":"/ai-sdk/docs/js/ai-core/ai-api"}}');var o=t(4848),a=t(8453);const s={id:"openai",title:"OpenAI Integration",hide_title:!1,hide_table_of_contents:!1,description:"How to integrate Azure OpenAI chat and embedding clients from SAP Cloud SDK for AI into LangChain.",keywords:["sap","cloud","sdk","ai","langchain","openai"]},r=void 0,l={},c=[{value:"Client Initialization",id:"client-initialization",level:2},{value:"Custom Destination",id:"custom-destination",level:3},{value:"Chat Completion",id:"chat-completion",level:2},{value:"Streaming",id:"streaming",level:3},{value:"Streaming with Abort Controller",id:"streaming-with-abort-controller",level:4},{value:"Tool Calling",id:"tool-calling",level:3},{value:"Embedding",id:"embedding",level:2},{value:"Embed Text",id:"embed-text",level:3},{value:"Embed Document Chunks",id:"embed-document-chunks",level:3},{value:"Preprocess, embed, and store documents",id:"preprocess-embed-and-store-documents",level:3},{value:"Resilience",id:"resilience",level:2},{value:"Retry",id:"retry",level:3},{value:"Timeout",id:"timeout",level:3}];function d(e){const n={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",h4:"h4",p:"p",pre:"pre",...(0,a.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.code,{children:"@sap-ai-sdk/langchain"})," packages provides ",(0,o.jsx)(n.code,{children:"AzureOpenAiChatClient"})," and ",(0,o.jsx)(n.code,{children:"AzureOpenAiEmbeddingClient"})," clients for LangChain integration with Azure OpenAI."]}),"\n",(0,o.jsx)(n.h2,{id:"client-initialization",children:"Client Initialization"}),"\n",(0,o.jsxs)(n.p,{children:["Both clients reuse the Azure OpenAI clients from ",(0,o.jsx)(n.code,{children:"@sap-ai-sdk/foundation-models"})," and implement ",(0,o.jsx)(n.a,{href:"https://js.langchain.com/docs/introduction",children:"LangChain's interface"}),".\nTherefore, the client initialization combines the configuration of the foundation model and LangChain options."]}),"\n",(0,o.jsxs)(n.p,{children:["Similar to the foundation model clients, the ",(0,o.jsx)(n.code,{children:"AzureOpenAiChatClient"})," and ",(0,o.jsx)(n.code,{children:"AzureOpenAiEmbeddingClient"})," LangChain clients can be initialized with model name and, by default, the latest model version."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-ts",children:"import {\n  AzureOpenAiChatClient,\n  AzureOpenAiEmbeddingClient\n} from '@sap-ai-sdk/langchain';\n\nconst chatClient = new AzureOpenAiChatClient({ modelName: 'gpt-4o' });\nconst embeddingClient = new AzureOpenAiEmbeddingClient({\n  modelName: 'text-embedding-3-small'\n});\n"})}),"\n",(0,o.jsxs)(n.p,{children:["Optionally, you can also specify model version, resource group and other parameters such as ",(0,o.jsx)(n.code,{children:"max_tokens"}),", ",(0,o.jsx)(n.code,{children:"temperature"})," and more."]}),"\n",(0,o.jsx)(n.admonition,{type:"note",children:(0,o.jsx)(n.p,{children:"Providing a deployment ID is currently not supported."})}),"\n",(0,o.jsx)(n.h3,{id:"custom-destination",children:"Custom Destination"}),"\n",(0,o.jsx)(n.p,{children:"When initializing the client, it is possible to provide a custom destination for your SAP AI Core instance."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-ts",children:"const chatClient = new AzureOpenAiChatClient(\n  {\n    modelName: 'gpt-4o'\n  },\n  {\n    destinationName: 'my-destination'\n  }\n);\n"})}),"\n",(0,o.jsxs)(n.p,{children:["By default, the fetched destination is cached.\nTo disable caching, set the ",(0,o.jsx)(n.code,{children:"useCache"})," parameter to ",(0,o.jsx)(n.code,{children:"false"})," together with the ",(0,o.jsx)(n.code,{children:"destinationName"})," parameter."]}),"\n",(0,o.jsxs)(n.p,{children:["For more information about configuring a destination, refer to the ",(0,o.jsx)(n.a,{href:"../connecting-to-ai-core#using-a-destination",children:"Using a Destination"})," section."]}),"\n",(0,o.jsx)(n.h2,{id:"chat-completion",children:"Chat Completion"}),"\n",(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.code,{children:"AzureOpenAiChatClient"})," allows interaction with Azure OpenAI chat models on SAP AI Core.\nPass a prompt to invoke the client."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-ts",children:'const response = await chatClient.invoke("What\'s the capital of France?");\n'})}),"\n",(0,o.jsx)(n.p,{children:"Below is an advanced example demonstrating the usage of templating and output parsing."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-ts",children:"import { AzureOpenAiChatClient } from '@sap-ai-sdk/langchain';\nimport { StringOutputParser } from '@langchain/core/output_parsers';\nimport { ChatPromptTemplate } from '@langchain/core/prompts';\n\n// Initialize the client\nconst chatClient = new AzureOpenAiChatClient({ modelName: 'gpt-4o' });\n\n// Create a prompt template\nconst promptTemplate = ChatPromptTemplate.fromMessages([\n  ['system', 'Answer the following in {language}:'],\n  ['user', '{text}']\n]);\n\n// Create an output parser\nconst parser = new StringOutputParser();\n\n// Chain together template, client and parser\nconst llmChain = promptTemplate.pipe(chatClient).pipe(parser);\n\n// Invoke the chain\nreturn llmChain.invoke({\n  language: 'german',\n  text: 'What is the capital of France?'\n});\n"})}),"\n",(0,o.jsx)(n.h3,{id:"streaming",children:"Streaming"}),"\n",(0,o.jsxs)(n.p,{children:["The client supports streaming responses for chat completion requests.\nUse the ",(0,o.jsx)(n.code,{children:"stream()"})," method to receive a stream of chunk responses from the model."]}),"\n",(0,o.jsx)(n.p,{children:"By default, the last chunk contains the finish reason and token usage information."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-ts",children:"const client = new AzureOpenAiChatClient({ modelName: 'gpt-4o' });\nconst response = await client.stream([\n  {\n    role: 'user',\n    content:\n      'Write a 100 word explanation about SAP Cloud SDK and its capabilities'\n  }\n]);\n\nlet finalResult: AIMessageChunk | undefined;\n\nfor await (const chunk of stream) {\n  console.log(chunk.content);\n  finalResult = finalResult ? finalResult.concat(chunk) : chunk;\n}\n\nconsole.log(finalResult?.response_metadata?.finish_reason);\n\nconsole.log(finalResult?.usage_metadata);\n/*\n  { input_tokens: 20, output_tokens: 126, total_tokens: 146 }\n*/\n\n// Token usage is also available in `response_metadata` property\nconsole.log(finalResult?.response_metadata?.token_usage);\n/*\n  {\n    completion_tokens: 126,\n    completion_tokens_details: {\n      accepted_prediction_tokens: 0,\n      audio_tokens: 0,\n      reasoning_tokens: 0,\n      rejected_prediction_tokens: 0\n    },\n    prompt_tokens: 20,\n    prompt_tokens_details: { audio_tokens: 0, cached_tokens: 0 },\n    total_tokens: 146\n  }\n*/\n"})}),"\n",(0,o.jsx)(n.h4,{id:"streaming-with-abort-controller",children:"Streaming with Abort Controller"}),"\n",(0,o.jsxs)(n.p,{children:["The client supports aborting streaming requests using the ",(0,o.jsx)(n.code,{children:"AbortController"})," API.\nIn case of an error, SAP Cloud SDK for AI will automatically close the stream.\nIt can also be manually aborted if an ",(0,o.jsx)(n.code,{children:"AbortSignal"})," object associated with an ",(0,o.jsx)(n.code,{children:"AbortController"})," was provided when calling the ",(0,o.jsx)(n.code,{children:"stream()"})," method."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-ts",children:"const client = new AzureOpenAiChatClient({ modelName: 'gpt-4o' });\nconst controller = new AbortController();\nconst { signal } = controller;\nconst response = await client.stream([\n  {\n    role: 'user',\n    content:\n      'Write a 100 word explanation about SAP Cloud SDK and its capabilities'\n  },\n  { signal }\n]);\n\n// Abort the streaming request after one second\nsetTimeout(() => {\n  controller.abort();\n}, 1000);\n\nfor await (const chunk of response) {\n  console.log(chunk.content);\n}\n"})}),"\n",(0,o.jsx)(n.p,{children:"In this example, streaming request will be aborted after one second.\nAbort controller can be useful, e.g., when end-user wants to stop the stream or refreshes the page."}),"\n",(0,o.jsx)(n.h3,{id:"tool-calling",children:"Tool Calling"}),"\n",(0,o.jsxs)(n.p,{children:["LangChain offers a unified way to connect tools to language models.\nUse the ",(0,o.jsx)(n.code,{children:"bindTools()"})," method to define the set of tools a model can access.\nFor more details, see the ",(0,o.jsx)(n.a,{href:"https://js.langchain.com/docs/concepts/tool_calling/#tool-binding",children:"official LangChain documentation on tool binding"}),".\nFor a usage example, refer to the ",(0,o.jsx)(n.a,{href:"../tutorials/getting-started-with-agents/langchain#define-mock-tools",children:"getting started with agents tutorial"}),"."]}),"\n",(0,o.jsx)(n.h2,{id:"embedding",children:"Embedding"}),"\n",(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.code,{children:"AzureOpenAiEmbeddingClient"})," allows embedding text or document chunks (represented as arrays of strings).\nWhile the embedding client can be used standalone, it is typically combined with other LangChain utilities, such as a text splitter for preprocessing and a vector store for storing and retrieving relevant embeddings.\nFor a complete example of how to implement RAG with the LangChain client, refer to the ",(0,o.jsx)(n.a,{href:"https://github.com/SAP/ai-sdk-js/blob/main/sample-code/src/langchain-azure-openai.ts",children:"sample code"}),"."]}),"\n",(0,o.jsx)(n.h3,{id:"embed-text",children:"Embed Text"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-ts",children:"const embeddedText = await embeddingClient.embedQuery(\n  'Paris is the capital of France.'\n);\n"})}),"\n",(0,o.jsx)(n.h3,{id:"embed-document-chunks",children:"Embed Document Chunks"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-ts",children:"const embeddedDocuments = await embeddingClient.embedDocuments([\n  'Page 1: Paris is the capital of France.',\n  'Page 2: It is a beautiful city.'\n]);\n"})}),"\n",(0,o.jsx)(n.h3,{id:"preprocess-embed-and-store-documents",children:"Preprocess, embed, and store documents"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-ts",children:"// Create a text splitter and split the document\nconst textSplitter = new RecursiveCharacterTextSplitter({\n  chunkSize: 2000,\n  chunkOverlap: 200\n});\nconst splits = await textSplitter.splitDocuments(docs);\n\n// Initialize the embedding client\nconst embeddingClient = new AzureOpenAiEmbeddingClient({\n  modelName: 'text-embedding-3-small'\n});\n\n// Create a vector store from the document\nconst vectorStore = await MemoryVectorStore.fromDocuments(\n  splits,\n  embeddingClient\n);\n\n// Create a retriever for the vector store\nconst retriever = vectorStore.asRetriever();\n"})}),"\n",(0,o.jsx)(n.h2,{id:"resilience",children:"Resilience"}),"\n",(0,o.jsxs)(n.p,{children:["Use LangChain options such as ",(0,o.jsx)(n.code,{children:"maxRetries"})," and ",(0,o.jsx)(n.code,{children:"timeout"})," to provide resilience."]}),"\n",(0,o.jsx)(n.h3,{id:"retry",children:"Retry"}),"\n",(0,o.jsxs)(n.p,{children:["By default, LangChain client retries up to six times with exponential delay.\nTo modify this behavior, set the ",(0,o.jsx)(n.code,{children:"maxRetries"})," option during the client initialization."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-ts",children:"const client = new AzureOpenAiChatClient({\n  modelName: 'gpt-4o',\n  maxRetries: 0\n});\n"})}),"\n",(0,o.jsx)(n.h3,{id:"timeout",children:"Timeout"}),"\n",(0,o.jsxs)(n.p,{children:["By default, no timeout is set in the client.\nTo limit the maximum duration for the entire request including retries, specify a timeout in milliseconds when calling the ",(0,o.jsx)(n.code,{children:"invoke"})," method."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-ts",children:"const response = await client.invoke(messageHistory, { timeout: 10000 });\n"})})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>r});var i=t(6540);const o={},a=i.createContext(o);function s(e){const n=i.useContext(a);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);