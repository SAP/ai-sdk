"use strict";(self.webpackChunksap_ai_sdk_documentation=self.webpackChunksap_ai_sdk_documentation||[]).push([[8407],{7807:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>l,contentTitle:()=>r,default:()=>d,frontMatter:()=>a,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"langchain/orchestration","title":"Orchestration Integration","description":"How to integrate orchestration client of SAP Cloud SDK for AI into LangChain.","source":"@site/docs-js/langchain/orchestration.mdx","sourceDirName":"langchain","slug":"/langchain/orchestration","permalink":"/ai-sdk/docs/js/next/langchain/orchestration","draft":false,"unlisted":false,"editUrl":"https://github.com/SAP/ai-sdk/edit/main/docs-js/langchain/orchestration.mdx","tags":[],"version":"current","frontMatter":{"id":"orchestration","title":"Orchestration Integration","hide_title":false,"hide_table_of_contents":false,"description":"How to integrate orchestration client of SAP Cloud SDK for AI into LangChain.","keywords":["sap","cloud","sdk","ai","langchain","orchestration"]},"sidebar":"docsJsSidebar","previous":{"title":"LangChain","permalink":"/ai-sdk/docs/js/next/langchain/"},"next":{"title":"OpenAI Integration","permalink":"/ai-sdk/docs/js/next/langchain/openai"}}');var o=t(4848),s=t(8453);const a={id:"orchestration",title:"Orchestration Integration",hide_title:!1,hide_table_of_contents:!1,description:"How to integrate orchestration client of SAP Cloud SDK for AI into LangChain.",keywords:["sap","cloud","sdk","ai","langchain","orchestration"]},r=void 0,l={},c=[{value:"Client Initialization",id:"client-initialization",level:2},{value:"Custom Destination",id:"custom-destination",level:3},{value:"Chat Completion",id:"chat-completion",level:2},{value:"Streaming",id:"streaming",level:3},{value:"Streaming with Abort Controller",id:"streaming-with-abort-controller",level:4},{value:"Tool Calling",id:"tool-calling",level:3},{value:"Resilience",id:"resilience",level:2},{value:"Retry",id:"retry",level:3},{value:"Timeout",id:"timeout",level:3}];function h(n){const e={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",h4:"h4",p:"p",pre:"pre",...(0,s.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsxs)(e.p,{children:["The ",(0,o.jsx)(e.code,{children:"@sap-ai-sdk/langchain"})," packages provides ",(0,o.jsx)(e.code,{children:"OrchestrationClient"})," client for LangChain integration with orchestration service."]}),"\n",(0,o.jsx)(e.h2,{id:"client-initialization",children:"Client Initialization"}),"\n",(0,o.jsxs)(e.p,{children:["The client reuses the orchestration client from ",(0,o.jsx)(e.code,{children:"@sap-ai-sdk/orchestration"})," and implements ",(0,o.jsx)(e.a,{href:"https://js.langchain.com/docs/introduction",children:"LangChain's interface"}),".\nTherefore, the client initialization combines the configuration of the orchestration client and LangChain options."]}),"\n",(0,o.jsxs)(e.p,{children:["Similar to the orchestration client, the ",(0,o.jsx)(e.code,{children:"OrchestrationClient"})," LangChain client can be initialized with an orchestration configuration.\nRefer to ",(0,o.jsx)(e.a,{href:"../orchestration/chat-completion",children:"Orchestration Chat Completion"})," for more information about the configuration."]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-ts",children:"import { OrchestrationClient } from '@sap-ai-sdk/langchain';\n\nconst config: OrchestrationModuleConfig = {\n  llm: {\n    model_name: 'gpt-4o'\n  }\n};\nconst client = new OrchestrationClient(config);\n"})}),"\n",(0,o.jsx)(e.p,{children:"Optionally, you can also specify LangChain options, resource group in deployment config, and a custom destination."}),"\n",(0,o.jsx)(e.h3,{id:"custom-destination",children:"Custom Destination"}),"\n",(0,o.jsx)(e.p,{children:"When initializing the client, it is possible to provide a custom destination for your SAP AI Core instance."}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-ts",children:"const client = new OrchestrationClient(\n  orchestrationConfig,\n  langchainOptions,\n  deploymentConfig,\n  { destinationName: 'my-destination' }\n);\n"})}),"\n",(0,o.jsxs)(e.p,{children:["By default, the fetched destination is cached.\nTo disable caching, set the ",(0,o.jsx)(e.code,{children:"useCache"})," parameter to ",(0,o.jsx)(e.code,{children:"false"})," together with the ",(0,o.jsx)(e.code,{children:"destinationName"})," parameter."]}),"\n",(0,o.jsxs)(e.p,{children:["For more information about configuring a destination, refer to the ",(0,o.jsx)(e.a,{href:"../connecting-to-ai-core#using-a-destination",children:"Using a Destination"})," section."]}),"\n",(0,o.jsx)(e.h2,{id:"chat-completion",children:"Chat Completion"}),"\n",(0,o.jsx)(e.p,{children:"Pass a message history and, in most cases, input parameters for the orchestration templating module."}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-ts",children:"const systemMessage = new SystemMessage('Be a helpful assistant!');\nconst history = [systemMessage];\nconst response = await client.invoke(history, {\n  inputParams: { subject: 'Paris' }\n});\n"})}),"\n",(0,o.jsx)(e.h3,{id:"streaming",children:"Streaming"}),"\n",(0,o.jsxs)(e.p,{children:["The client supports streaming responses for chat completion requests.\nUse the ",(0,o.jsx)(e.code,{children:"stream()"})," method to receive a stream of chunk responses from the model."]}),"\n",(0,o.jsx)(e.p,{children:"By default, the last chunk contains the finish reason and token usage information."}),"\n",(0,o.jsx)(e.admonition,{type:"warning",children:(0,o.jsx)(e.p,{children:"The orchestration service currently doesn't support multiple choices during streaming."})}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-ts",children:"const orchestrationConfig: LangchainOrchestrationModuleConfig = {\n  llm: {\n    model_name: 'gpt-4o'\n  }\n};\n\nconst client = new OrchestrationClient(orchestrationConfig);\nconst response = await client.stream([\n  {\n    role: 'user',\n    content:\n      'Write a 100 word explanation about SAP Cloud SDK and its capabilities'\n  }\n]);\n\nlet finalResult: AIMessageChunk | undefined;\n\nfor await (const chunk of response) {\n  console.log(chunk.content);\n  finalResult = finalResult ? finalResult.concat(chunk) : chunk;\n}\n\nconsole.log(finalResult?.response_metadata?.finish_reason);\n\nconsole.log(finalResult?.usage_metadata);\n/*\n  { input_tokens: 13, output_tokens: 30, total_tokens: 43 }\n*/\n\n// Token usage is also available in `response_metadata` property\nconsole.log(finalResult?.response_metadata?.token_usage);\n/*\n  { completion_tokens: 30, prompt_tokens: 13, total_tokens: 43 }\n*/\n"})}),"\n",(0,o.jsx)(e.h4,{id:"streaming-with-abort-controller",children:"Streaming with Abort Controller"}),"\n",(0,o.jsxs)(e.p,{children:["The client supports aborting streaming requests using the ",(0,o.jsx)(e.code,{children:"AbortController"})," API.\nIn case of an error, SAP Cloud SDK for AI will automatically close the stream.\nIt can also be manually aborted if an ",(0,o.jsx)(e.code,{children:"AbortSignal"})," object associated with an ",(0,o.jsx)(e.code,{children:"AbortController"})," was provided when calling the ",(0,o.jsx)(e.code,{children:"stream()"})," method."]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-ts",children:"const orchestrationConfig: LangchainOrchestrationModuleConfig = {\n  llm: {\n    model_name: 'gpt-4o'\n  }\n};\n\nconst client = new OrchestrationClient(orchestrationConfig);\nconst controller = new AbortController();\nconst { signal } = controller;\nconst response = await client.stream([\n  {\n    role: 'user',\n    content:\n      'Write a 100 word explanation about SAP Cloud SDK and its capabilities'\n  },\n  { signal }\n]);\n\n// Abort the streaming request after one second\nsetTimeout(() => {\n  controller.abort();\n}, 1000);\n\nfor await (const chunk of response) {\n  console.log(chunk.content);\n}\n"})}),"\n",(0,o.jsx)(e.p,{children:"In this example, streaming request will be aborted after one second.\nAbort controller can be useful, e.g., when end-user wants to stop the stream or refreshes the page."}),"\n",(0,o.jsx)(e.h3,{id:"tool-calling",children:"Tool Calling"}),"\n",(0,o.jsxs)(e.p,{children:["LangChain offers a unified way to connect tools to language models.\nUse the ",(0,o.jsx)(e.code,{children:"bindTools()"})," method to define the set of tools a model can access.\nFor more details, see the ",(0,o.jsx)(e.a,{href:"https://js.langchain.com/docs/concepts/tool_calling/#tool-binding",children:"official LangChain documentation on tool binding"}),".\nFor a usage example, refer to the ",(0,o.jsx)(e.a,{href:"../tutorials/getting-started-with-agents/langchain#define-mock-tools",children:"getting started with agents tutorial"}),"."]}),"\n",(0,o.jsx)(e.h2,{id:"resilience",children:"Resilience"}),"\n",(0,o.jsxs)(e.p,{children:["Use LangChain options such as ",(0,o.jsx)(e.code,{children:"maxRetries"})," and ",(0,o.jsx)(e.code,{children:"timeout"})," to provide resilience."]}),"\n",(0,o.jsx)(e.h3,{id:"retry",children:"Retry"}),"\n",(0,o.jsxs)(e.p,{children:["By default, LangChain client retries up to six times with exponential delay.\nTo modify this behavior, set the ",(0,o.jsx)(e.code,{children:"maxRetries"})," option during the client initialization."]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-ts",children:"const client = new OrchestrationClient(orchestrationConfig, {\n  maxRetries: 0\n});\n"})}),"\n",(0,o.jsx)(e.admonition,{type:"note",children:(0,o.jsx)(e.p,{children:"If the error is caused by input content filtering, the client will throw immediately without retrying."})}),"\n",(0,o.jsx)(e.h3,{id:"timeout",children:"Timeout"}),"\n",(0,o.jsxs)(e.p,{children:["By default, no timeout is set in the client.\nTo limit the maximum duration for the entire request including retries, specify a timeout in milliseconds when calling the ",(0,o.jsx)(e.code,{children:"invoke"})," method.\nA request that times out will be ",(0,o.jsx)(e.a,{href:"#retry",children:"retried"})," by default."]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-ts",children:"const response = await client.invoke(messageHistory, { timeout: 10000 });\n"})}),"\n",(0,o.jsx)(e.p,{children:"Timeout can also be set for streaming requests."}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-ts",children:"const response = await client.stream(\n  [\n    {\n      role: 'user',\n      content: 'Hello world! Why is this phrase so famous?'\n    }\n  ],\n  { timeout: 1000 }\n);\n"})})]})}function d(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(h,{...n})}):h(n)}},8453:(n,e,t)=>{t.d(e,{R:()=>a,x:()=>r});var i=t(6540);const o={},s=i.createContext(o);function a(n){const e=i.useContext(s);return i.useMemo((function(){return"function"==typeof n?n(e):{...e,...n}}),[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:a(n.components),i.createElement(s.Provider,{value:e},n.children)}}}]);