---
id: rpt
title: SAP RPT-1 (Beta)
hide_title: false
hide_table_of_contents: false
description: How to use SAP Cloud SDK for AI to interact with the SAP RPT-1 model for Tabular AI on SAP AI Core.
keywords:
  - sap
  - cloud
  - sdk
  - ai
  - ai core
  - ai-api
  - rpt
  - rpt-1
  - tabular ai
  - relational pretrained transformer
---

:::important
This package is experimental and subject to change.
Do not use in production.
:::

The `@sap-ai-sdk/rpt` package provides a client to interact with SAP's SAP-RPT-1 relational pretrained transformer model, [SAP-RPT-1](https://www.sap.com/products/artificial-intelligence/sap-rpt.html).
Technically, SAP-RPT-1 is a foundation model, but the client is provided in a separate package.

## Installation

To add the SAP Cloud SDK for AI RPT client to your project, run the following command in your terminal:

```bash
npm install @sap-ai-sdk/rpt
```

## Usage

SAP-RPT-1's purpose is to predict structured business data.
The following shows the different ways to use the SAP Cloud SDK for AI RPT client to interact with the model.

### Client Initialization

To initialize a client use the `RptClient` constructor.
All parameters are optional.
By default, this uses the 'sap-rpt-1-small' model.

```typescript
import { RptClient } from '@sap-ai-sdk/rpt';

const client = new RptClient();
```

To use the 'sap-rpt-1-large' model, specify the model name in the constructor:

```typescript
const client = new RptClient('sap-rpt-1-large');
```

To configure a model version, deployment ID, resource group or destination follow the instructions in the [Foundation Models documentation](../foundation-models#client-initialization).

### Predict With Schema

To make predictions with a schema, use the `predict()` method.
Pass the data schema and the prediction data, i.e. prediction configuration and input data, as parameters.

```typescript
const prediction = await client.predictWithSchema(
  // Data schema
  [
    { name: 'PRODUCT', dtype: 'string' },
    { name: 'PRICE', dtype: 'numeric' },
    { name: 'PRODUCTION_DATE', dtype: 'date' },
    { name: 'SALESGROUP', dtype: 'string' }
  ],
  // Prediction data
  {
    prediction_config: {
      target_columns: [
        {
          name: 'SALESGROUP',
          prediction_placeholder: '[PREDICT]',
          task_type: 'classification'
        }
      ]
    },
    index_column: '__row_idx__',
    rows: [
      {
        PRODUCT: 'Laptop',
        PRICE: 999.99,
        PRODUCTION_DATE: '2025-01-15',
        __row_idx__: '35',
        SALESGROUP: '[PREDICT]'
      },
      {
        PRODUCT: 'Desktop Computer',
        PRICE: 750.5,
        PRODUCTION_DATE: '2024-12-02',
        __row_idx__: '42',
        SALESGROUP: 'Enterprise Solutions'
      }
      // Additional rows...
    ]
  }
);
```

The data schema is a list of column definitions, each containing a `name` and a `dtype`.
The prediction data contains the following properties:

- `prediction_config`: A mandatory configuration to specify the columns to predict, including their names, placeholder values, and task types.
  The task type can be either `classification` or `regression`. If not specified, the model infers the task type based on the column data type.
- `index_column`: The name of the column that serves as the unique identifier for each row.
  The index column is returned in the prediction results to allow mapping predictions back to the input data.
- `rows` or `columns`: The input data to make predictions on.
  Use `rows` for row-based format or `columns` for column-based format.
- `parse_data_types`: Optional boolean to control data type parsing.
  When `true` (default), numeric columns are parsed to float or integer, and dates (`YYYY-MM-DD`) are parsed automatically.

:::important
When assigning schema and prediction data as variables, initialize the schema with `as const` and use the `PredictionData<typeof schema>` type.
This is not required when passing data directly to the `predictWithSchema()` method.
Example:

```typescript
const schema = [...] as const;
const data: PredictionData<typeof schema> = {...};

client.predictWithSchema(schema, data);
```

:::

### Predict Without Schema

:::tip

If the data schema is known, it is recommended to use the [`predictWithSchema()` method](#predict-with-schema) instead.

:::

To make predictions without providing a schema, use the `predictWithoutSchema()` method.
Pass only the prediction data as a parameter.
The data schema will be inferred from the input data.

```typescript
const prediction = await client.predictWithoutSchema(
  // Prediction data
  {
    prediction_config: {
      target_columns: [
        { name: 'SALESGROUP', prediction_placeholder: '[PREDICT]', task_type: 'classification' }
      ]
    },
    index_column: '__row_idx__',
    rows: [
      {
        PRODUCT: 'Laptop',
        PRICE: 999.99,
        PRODUCTION_DATE: '2025-01-15',
        __row_idx__: '35',
        SALESGROUP: '[PREDICT]'
      },
      {
        PRODUCT: 'Desktop Computer',
        PRICE: 750.5,
        PRODUCTION_DATE: '2024-12-02',
        __row_idx__: '42',
        SALESGROUP: 'Enterprise Solutions'
      },
      ...
    ]
  }
);
```

### Predict with Parquet

[Parquet](https://parquet.apache.org) is a tabular file format optimized for data-science workloads.
To make predictions on Parquet files, use the `predictParquet()` method.
Pass the Parquet file as a `Blob` along with the prediction configuration.
Optional arguments such as `index_column` and `parse_data_types` can be specified in the third parameter.

```typescript
import { openAsBlob } from 'node:fs';

const parquetBlob = await openAsBlob('path/to/input-data.parquet');
const client = new RptClient();

const prediction = await client.predictParquet(parquetBlob, {
  target_columns: [
    { name: 'SALESGROUP', prediction_placeholder: '[PREDICT]', task_type: 'classification' }
  ]
},
{
  index_column: '__row_idx__',
  parse_data_types: false 
});
```
