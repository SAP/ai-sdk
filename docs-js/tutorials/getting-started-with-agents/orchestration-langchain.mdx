---
id: orchestration-langchain-agents
title: Getting Started with Agents using LangChain for Orchestration
sidebar_label: LangChain Orchestration
description: Building a Travel Itinerary Assistant with LangGraph and LangChain Orchestration Client
keywords:
  - tutorial
  - agents
  - langgraph
  - orchestration
---

# Introduction

In this tutorial, you'll build a simple travel assistant agent using the LangChain Orchestration Client (`Orchestration`) from the `@sap-ai-sdk/langchain` package alongside `LangGraph`.
The agent creates an itinerary based on current weather conditions and supports follow-up queries.

The assistant performs these steps:

- Accepts a user travel request.
- Calls a weather tool to get the current weather for the city.
- Generates a weather-aware 3-item itinerary.
- Handles follow-up questions like restaurant recommendations using conversation memory.

# Prerequisites

Refer to prerequisites outlined [here](../overview-cloud-sdk-for-ai-js#prerequisites).

This tutorial assumes you have a basic understanding of TypeScript, LLMs and LangChain concepts.

## Installation

Install the following dependencies:

```bash
npm install @sap-ai-sdk/langchain langchain @langchain/langgraph @langchain/core zod
```

## Define Mock Tools

Define two custom tools for weather and restaurant data.

- `get_weather` for returning weather by city
- `get_restaurants` for city-based restaurant recommendations

```ts
import { tool } from '@langchain/core/tools';
import { z } from 'zod';

const mockWeatherData: Record<
  string,
  { temperature: string; condition: string }
> = {
  paris: { temperature: '22°C', condition: 'Mild and pleasant' },
  reykjavik: { temperature: '3°C', condition: 'Cold and windy' }
};

const mockRestaurantData: Record<string, string[]> = {
  paris: ['Le Comptoir du Relais', "L'As du Fallafel", 'Breizh Café'],
  reykjavik: ['Dill Restaurant', 'Fish Market', 'Grillmarkaðurinn']
};

const getWeatherTool = tool(
  async ({ city }) => {
    const weather = mockWeatherData[city.toLowerCase()];
    return weather
      ? `Current weather in ${city}: ${weather.temperature}, ${weather.condition}`
      : `Weather data not available for ${city}.`;
  },
  {
    name: 'get_weather',
    description: 'Get current weather information for a city',
    schema: z.object({ city: z.string().describe('The city name') })
  }
);

const getRestaurantsTool = tool(
  async ({ city }) => {
    const restaurants = mockRestaurantData[city.toLowerCase()];
    return restaurants
      ? `Popular restaurants in ${city}: ${restaurants.join(', ')}`
      : `No restaurant data available for ${city}.`;
  },
  {
    name: 'get_restaurants',
    description: 'Get restaurant recommendations for a city',
    schema: z.object({ city: z.string().describe('The city name') })
  }
);
```

:::info
This example uses mocked data for simplicity.
Replace the tools' implementation with real API calls to integrate live data.
:::

## Setup the Agent

Initialize the `AzureOpenAiChatClient` and add tools using the `buildTools()` method.
Set up a `ToolNode` for routing tool calls.

```ts
import { AzureOpenAiChatClient } from '@sap-ai-sdk/langchain';
import { ToolNode } from '@langchain/langgraph/prebuilt';

const tools = [getWeatherTool, getRestaurantsTool];

const model = new AzureOpenAiChatClient({
  modelName: 'gpt-4o',
  temperature: 0.7
}).bindTools(tools);

const toolNode = new ToolNode(tools);
```

## Define Agent Logic and LangGraph Flow

Configure a `StateGraph` that routes between `agent` → `tool` → `agent`, and ends when no more tool calls are needed.

```ts
import {
  StateGraph,
  MessagesAnnotation,
  MemorySaver,
  START
} from '@langchain/langgraph';
import { AIMessage } from '@langchain/core/messages';

function shouldContinue({ messages }: typeof MessagesAnnotation.State) {
  const lastMessage = messages[messages.length - 1] as AIMessage;
  return lastMessage.tool_calls?.length ? 'tools' : '__end__';
}

async function callModel(state: typeof MessagesAnnotation.State) {
  const response = await model.invoke(state.messages);
  return { messages: [response] };
}

const workflow = new StateGraph(MessagesAnnotation)
  .addNode('agent', callModel)
  .addEdge(START, 'agent')
  .addNode('tools', toolNode)
  .addEdge('tools', 'agent')
  .addConditionalEdges('agent', shouldContinue);

const memory = new MemorySaver();
const app = workflow.compile({ checkpointer: memory });
```

:::note
Using [`MemorySaver`](https://langchain-ai.github.io/langgraphjs/how-tos/persistence/?h=memory+saver#add-memory) allows sharing context across multiple interactions in a single conversational thread (`conv-1`).
In this example, it enables the agent to remember the previously mentioned city.
:::

## Run the assistant

The following example simulates a conversation:

1. The assistant receives an itinerary request.
2. It retrieves the weather before generating a plan.
3. A follow-up message requests restaurant recommendations for the same city.

```ts
import { HumanMessage, SystemMessage } from '@langchain/core/messages';

const config = { configurable: { thread_id: 'conv-1' } };

async function runTravelAssistant() {
  // Initial system prompt and user message
  let messages = [
    new SystemMessage(
      'You are a helpful travel assistant. Create a short, practical 3-item itinerary based on the city. Always check the weather before suggesting an itinerary.'
    ),
    new HumanMessage(
      "I'm traveling to Paris. Can you help me prepare an itinerary?"
    )
  ];

  // First interaction - triggers weather tool and itinerary generation
  let response = await app.invoke({ messages }, config);
  console.log('Assistant:', response.messages[response.messages.length - 1]);

  // Continue conversation - add restaurant question
  messages = [new HumanMessage('Can you also recommend some restaurants?')];

  // Second interaction - should remember Paris and call restaurant tool
  response = await app.invoke({ messages }, config);
  console.log('Assistant:', response.messages[response.messages.length - 1]);
}
```

## Summary

This tutorial demonstrates how to implement a simple agent workflow using:

- The `AzureOpenAiChatClient` with `bindTools()` method to integrate external capabilities.
- A `StateGraph` to manage agent-tool flow and decisions, and `MemorySaver` for multi-turn memory retention.

Explore additional capabilities and patterns in [LangGraph documentation](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/).
