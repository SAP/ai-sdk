---
id: getting-started-with-agents
title: Getting Started with Agents using LangChain
sidebar_label: Getting Started with Agents
description: Building a Travel Itinerary Assistant with LangGraph and LangChain Client
keywords:
  - tutorial
  - agents
  - langgraph
  - langchain
  - openai
  - orchestration
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

## Introduction

In this tutorial, you'll build a simple travel assistant agent using a LangChain Client, either `OrchestrationClient` or `AzureOpenAiChatClient` from the `@sap-ai-sdk/langchain` package alongside `LangGraph`.
The agent creates an itinerary based on current weather conditions and supports follow-up queries.

The assistant performs these steps:

- Accepts a user travel request.
- Calls a weather tool to fetch the current weather.
- Creates a weather-aware 3-item itinerary, including restaurant recommendations.
- Asks for human input (via interruption) when confirmation is required.

## Prerequisites

Refer to prerequisites outlined [here](../../overview-cloud-sdk-for-ai-js#prerequisites).

This tutorial assumes you have a basic understanding of TypeScript, LLMs and LangChain concepts.

## Installation

Install the following dependencies:

```bash
npm install @sap-ai-sdk/langchain langchain @langchain/langgraph @langchain/core zod
```

## Define Mock Tools

Define tools:

- `get_weather` for returning weather by city
- `get_restaurants` for city-based restaurant recommendations

:::info
This example uses mocked data for simplicity.
Replace the tools' implementation with real API calls to integrate live data.
:::

```ts
import { tool } from '@langchain/core/tools';
import { z } from 'zod';

const mockWeatherData: Record<
  string,
  { temperature: string; condition: string }
> = {
  paris: { temperature: '22Â°C', condition: 'Mild and pleasant' },
  reykjavik: { temperature: '3Â°C', condition: 'Cold and windy' }
};

const mockRestaurantData: Record<string, string[]> = {
  paris: ['Le Comptoir du Relais', "L'As du Fallafel", 'Breizh CafÃ©'],
  reykjavik: ['Dill Restaurant', 'Fish Market', 'GrillmarkaÃ°urinn']
};

const getWeatherTool = tool(
  async ({ city }) => {
    const weather = mockWeatherData[city.toLowerCase()];
    return weather
      ? `Current weather in ${city}: ${weather.temperature}, ${weather.condition}`
      : `Weather data not available for ${city}.`;
  },
  {
    name: 'get_weather',
    description: 'Get current weather information for a city',
    schema: z.object({ city: z.string().describe('The city name') })
  }
);

const getRestaurantsTool = tool(
  async ({ city }) => {
    const restaurants = mockRestaurantData[city.toLowerCase()];
    return restaurants
      ? `Popular restaurants in ${city}: ${restaurants.join(', ')}`
      : `No restaurant data available for ${city}.`;
  },
  {
    name: 'get_restaurants',
    description: 'Get restaurant recommendations for a city',
    schema: z.object({ city: z.string().describe('The city name') })
  }
);
```

## Setup the Agent

Initialize the client and add tools using the `buildTools()` method.
Set up a `ToolNode` for routing tool calls.

<Tabs 
  groupId="client"
  defaultValue="orchestration"
  values={[
    {label: "Orchestration Client", value: "orchestration"},
    {label: "OpenAI Client", value: "openai"}
  ]}>
<TabItem value="openai">

```ts
import { AzureOpenAiChatClient } from '@sap-ai-sdk/langchain';
import { ToolNode } from '@langchain/langgraph/prebuilt';

const tools = [getWeatherTool, getRestaurantsTool];

// Create a model
const model = new AzureOpenAiChatClient({
  modelName: 'gpt-4o',
  temperature: 0.7
});

// create a model with access to the tools
const modelWithTools = model.bindTools(tools);

const toolNode = new ToolNode(tools);
```

</TabItem>
<TabItem value="orchestration">

```ts
import { OrchestrationClient } from '@sap-ai-sdk/langchain';
import { ToolNode } from '@langchain/langgraph/prebuilt';

const tools = [getWeatherTool, getRestaurantsTool];

// Create a model
const model = new OrchestrationClient({
  modelName: 'gpt-4o',
  temperature: 0.7
});

// create a model with access to the tools
const modelWithTools = model.bindTools(tools);

const toolNode = new ToolNode(tools);
```

</TabItem>
</Tabs>

## Define Agent Logic and LangGraph Flow

Configure a `StateGraph` that routes between `agent` â†’ `tool` â†’ `agent`, and uses intelligent routing to determine when to ask for human input or end the conversation.

```ts
import {
  StateGraph,
  MessagesAnnotation,
  MemorySaver,
  START,
  interrupt,
  END
} from '@langchain/langgraph';
import { AIMessage } from '@langchain/core/messages';

async function shouldContinueAgent({
  messages
}: typeof MessagesAnnotation.State) {
  const lastMessage = messages.at(-1) as AIMessage;

  // If there are tool calls, go to tools
  if (lastMessage.tool_calls?.length) {
    return 'tools';
  }
  // Check if agent's message is a farewell (indicating user was satisfied)
  const result = await model.invoke([
    new SystemMessage(
      'You are a classifier. Respond with exactly "FAREWELL" if this is a farewell/goodbye message wishing someone happy travels. Respond with exactly "CONTINUE" if the conversation should continue.'
    ),
    new HumanMessage(`Assistant message: "${lastMessage.content}"`)
  ]);

  return result.content === 'FAREWELL' ? END : 'askHuman';
}

async function askHuman() {
  // This is where the actual interrupt happens
  const humanResponse: string = interrupt(
    `Do you want to adjust the itinerary?`
  );
  return { messages: [new HumanMessage(humanResponse)] };
}

async function callModel({ messages }: typeof MessagesAnnotation.State) {
  const response = await model.invoke(messages);
  return { messages: [response] };
}
```

## Build the Workflow

```ts
const workflow = new StateGraph(MessagesAnnotation)
  .addNode('agent', callModel)
  .addNode('tools', toolNode)
  .addNode('askHuman', askHuman)
  .addConditionalEdges('agent', shouldContinue, ['tools', 'askHuman', END])
  .addEdge('tools', 'agent')
  .addEdge('askHuman', 'agent')
  .addEdge(START, 'agent');

const memory = new MemorySaver();
const app = workflow.compile({ checkpointer: memory });
```

:::note
Using [`MemorySaver`](https://langchain-ai.github.io/langgraphjs/how-tos/persistence/?h=memory+saver#add-memory) allows sharing context across multiple interactions in a single conversational thread (`conv-1`).
In this example, it enables the agent to remember the previously mentioned city.
:::

## Run the assistant

The following example simulates a full interaction, with detailed console output at each step:

1. The assistant receives an initial itinerary request and fetches weather data.
2. It creates a weather-aware itinerary with restaurant recommendations and asks for user feedback.
3. It handles follow-up requests and modifications based on user input.
4. The conversation continues until the user is satisfied.

```ts
import { HumanMessage, SystemMessage } from '@langchain/core/messages';
import { Command } from '@langchain/langgraph';

const config = { configurable: { thread_id: 'conv-1' } };

// Initial system prompt and user message
const initMessages = [
  new SystemMessage(
    `You are a helpful travel assistant.
        You will generate a 3-item itinerary based on a provided city. You should use weather forecast and restaurant recommendations when creating the itinerary.
        After presenting the itinerary, ask the user if they are satisfied with it or if they want to make changes.`
  ),
  new HumanMessage(
    "I'm traveling to Paris. Can you help me prepare an itinerary?"
  )
];

try {
  let response = await app.invoke({ messages: initMessages }, config);
```

When the agent receives the initial request, it first determines that it needs both weather and restaurant data to create a comprehensive itinerary.
The LLM response includes tool calls to gather this information:

```json
"tool_calls": [
  {
    "id": "call_bnMuoAGpN6zUnpEm1DwqykvV",
    "name": "get_weather",
    "args": {
      "city": "Paris"
    },
    "type": "tool_call"
  },
  {
    "id": "call_NnlDugZMjAd4JrSqBa4lFpHE",
    "name": "get_restaurants",
    "args": {
      "city": "Paris"
    },
    "type": "tool_call"
  }
]
```

The agent executes these tool calls through the `tools` node to gather the necessary data, then returns to the agent node to generate a natural language response with the complete itinerary.

```ts
console.log('Assistant:', response.messages.at(-1)?.content);
console.log('next: ', (await app.getState(config)).next);
```

```console
Assistant: Here's a 3-item itinerary for your visit to Paris:

1. **Morning: Explore the Louvre Museum**
   - Start your day by visiting the world-renowned Louvre Museum. Take your time to explore its vast collection of art and history.
   - Weather: 22Â°C, Mild and pleasant â€“ perfect for a stroll through the museum and its gardens.

2. **Afternoon: Lunch at Le Comptoir du Relais**
   - Enjoy a delicious lunch at Le Comptoir du Relais, a popular Parisian restaurant known for its authentic French cuisine.
   - After lunch, you can take a leisurely walk around the nearby Saint-Germain-des-PrÃ©s area, soaking in the Parisian ambiance.

3. **Evening: Dinner at L'As du Fallafel**
   - Head to L'As du Fallafel for dinner, where you can savor some of the best falafel in the city. It's a unique spot that offers a taste of multicultural Paris.
   - You can conclude your evening with a walk in the vibrant Marais district, where the restaurant is located.

Would you like to make any changes to this itinerary or add something else?
```

After presenting the itinerary, the graph pauses at the `askHuman` node and waits for the human's response.

```bash
next:  [ 'askHuman' ]
```

Provide the response by invoking the graph with a `new Command({ resume: <follow_up_question>" })` input:

```ts
response = await app.invoke(
  new Command({ resume: 'Can you suggest something more outdorsy?' }),
  config
);

console.log('Assistant:', response.messages.at(-1).content);
```

The assistant responds with an updated itinerary:

```console
Assistant: Here's an updated itinerary with more outdoor activities:

1. **Morning: Visit the Eiffel Tower and Picnic at Champ de Mars**
   - Start your day with a visit to the iconic Eiffel Tower. You can either marvel at its structure from below or take a ride to the top for breathtaking views of Paris.
   - Weather: 22Â°C, Mild and pleasant â€“ ideal for an outdoor picnic.
   - After the visit, enjoy a relaxing picnic at the nearby Champ de Mars park, where you can unwind and soak in the views.

2. **Afternoon: Stroll Along the Seine River**
   - Spend your afternoon walking along the Seine River. You can admire the beautiful bridges and architecture, and maybe even catch a boat tour for a different perspective of the city.
   - Stop by a local cafÃ© for a light lunch or grab a snack from one of the nearby street vendors.

3. **Evening: Dinner at Breizh CafÃ©**
   - Conclude your day with dinner at Breizh CafÃ©, known for its delicious crÃªpes. It's located in a charming area where you can enjoy a pleasant outdoor dining experience.
   - After dinner, take a leisurely walk through the lively streets of the Marais district and enjoy the evening atmosphere.

Does this itinerary suit your preferences, or would you like further adjustments?
```

The agent loop ends when the user expresses satisfaction with the proposed itinerary.

```ts
  response = await app.invoke(new Command({ resume: 'Great! Looks perfect' }), config);

  console.log('Assistant:', response.messages.at(-1)?.content);

  } catch (error) {
    console.error('Error:', error);
  }
```

```console
Assistant: I'm glad you like the itinerary! If you have any more questions or need further assistance while planning your trip, feel free to reach out. Enjoy your time in Paris! Safe travels! ðŸŒŸ
```

## Full Code

<details>
<summary>Travel Itinerary Planner Agent</summary>

```ts
import {
  StateGraph,
  MessagesAnnotation,
  MemorySaver,
  START,
  END,
  interrupt,
  Command
} from '@langchain/langgraph';
import { ToolNode } from '@langchain/langgraph/prebuilt';
import { AzureOpenAiChatClient } from '@sap-ai-sdk/langchain';
import { HumanMessage, SystemMessage } from '@langchain/core/messages';
import { tool } from '@langchain/core/tools';
import { z } from 'zod';
import type { AIMessage } from '@langchain/core/messages';
/**
 * This example demonstrates how to create a travel itinerary assistant using LangGraph.
 * The assistant can check the weather and recommend restaurants based on the city provided.
 * It uses tools to fetch weather and restaurant data, and maintains conversation context.
 */
const mockWeatherData: Record<
  string,
  { temperature: string; condition: string }
> = {
  paris: { temperature: '22Â°C', condition: 'Mild and pleasant' },
  reykjavik: { temperature: '3Â°C', condition: 'Cold and windy' }
};

const mockRestaurantData: Record<string, string[]> = {
  paris: ['Le Comptoir du Relais', "L'As du Fallafel", 'Breizh CafÃ©'],
  reykjavik: ['Dill Restaurant', 'Fish Market', 'GrillmarkaÃ°urinn']
};

const getWeatherTool = tool(
  async ({ city }) => {
    const weather = mockWeatherData[city.toLowerCase()];
    return weather
      ? `Current weather in ${city}: ${weather.temperature}, ${weather.condition}`
      : `Weather data not available for ${city}.`;
  },
  {
    name: 'get_weather',
    description: 'Get current weather information for a city',
    schema: z.object({ city: z.string().describe('The city name') })
  }
);

const getRestaurantsTool = tool(
  async ({ city }) => {
    const restaurants = mockRestaurantData[city.toLowerCase()];
    return restaurants
      ? `Popular restaurants in ${city}: ${restaurants.join(', ')}`
      : `No restaurant data available for ${city}.`;
  },
  {
    name: 'get_restaurants',
    description: 'Get restaurant recommendations for a city',
    schema: z.object({ city: z.string().describe('The city name') })
  }
);

// Define the tools for the agent to use
const tools = [getWeatherTool, getRestaurantsTool];
const toolNode = new ToolNode(tools);

// Create a model
const model = new AzureOpenAiChatClient({
  modelName: 'gpt-4o',
  temperature: 0.7
});

// create a model with access to the tools
const modelWithTools = model.bindTools(tools);

async function shouldContinueAgent({
  messages
}: typeof MessagesAnnotation.State) {
  const lastMessage = messages.at(-1) as AIMessage;

  // If there are tool calls, go to tools
  if (lastMessage.tool_calls?.length) {
    return 'tools';
  }
  // Check if agent's message is a farewell (indicating user was satisfied)
  const result = await model.invoke([
    new SystemMessage(
      'You are a classifier. Respond with exactly "FAREWELL" if this is a farewell/goodbye message wishing someone happy travels. Respond with exactly "CONTINUE" if the conversation should continue.'
    ),
    new HumanMessage(`Assistant message: "${lastMessage.content}"`)
  ]);

  return result.content === 'FAREWELL' ? END : 'askHuman';
}

async function askHuman() {
  // This is where the actual interrupt happens
  const humanResponse: string = interrupt(
    'Do you want to adjust the itinerary?'
  );
  return { messages: [new HumanMessage(humanResponse)] };
}

async function callModel({ messages }: typeof MessagesAnnotation.State) {
  const response = await modelWithTools.invoke(messages);
  return { messages: [response] };
}

const workflow = new StateGraph(MessagesAnnotation)
  .addNode('agent', callModel)
  .addNode('tools', toolNode)
  .addNode('askHuman', askHuman)
  .addConditionalEdges('agent', shouldContinueAgent, ['tools', 'askHuman', END])
  .addEdge('tools', 'agent')
  .addEdge('askHuman', 'agent')
  .addEdge(START, 'agent');

const memory = new MemorySaver();
const app = workflow.compile({ checkpointer: memory });

const config = { configurable: { thread_id: 'conv-1' } };

// Initial system prompt and user message
const initMessages = [
  new SystemMessage(
    `You are a helpful travel assistant.  
        You will generate a 3-item itinerary based on a provided city. You should use weather forecast and restaurant recommendations when creating the itinerary.
        After presenting the itinerary, ask the user if they are satisfied with it or if they want to make changes.`
  ),
  new HumanMessage(
    "I'm traveling to Paris. Can you help me prepare an itinerary?"
  )
];

// Start the agent with initial messages
try {
  let response = await app.invoke({ messages: initMessages }, config);

  console.log('Assistant:', response.messages.at(-1)?.content);
  console.log('next: ', (await app.getState(config)).next);

  response = await app.invoke(
    new Command({ resume: 'Can you suggest something more outdoorsy?' }),
    config
  );

  console.log('Assistant:', response.messages.at(-1)?.content);

  response = await app.invoke(
    new Command({ resume: 'Great! Looks perfect' }),
    config
  );
  console.log('Assistant:', response.messages.at(-1)?.content);
} catch (error) {
  console.error('Error:', error);
}
```

</details>

## Summary

This tutorial demonstrates how to implement a simple agent workflow using:

- The `AzureOpenAiChatClient` with `bindTools()` method to integrate external capabilities.
- Defining a LangGraph `StateGraph` for branching logic and conditional tool use.
- Interrupting the flow with a human tool via `interrupt()` and handling it inside the graph.
- Maintaining context across interactions with `MemorySaver`.

Explore additional capabilities and patterns in [LangGraph documentation](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/).
